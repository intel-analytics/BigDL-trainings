{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Network on the Iris Dataset\n",
    "# Using Pipeline API\n",
    "\n",
    "Fisher's Iris dataset  \n",
    "\n",
    "We are going to try the same Iris dataset as on feedforward-iris.ipynb, but this time using\n",
    "Spark MLLib's Pipeline-based API.\n",
    "\n",
    "This dataset contains 150 samples, with 4 dimensions, as follows:\n",
    "\n",
    "1. Petal Length  (c1)\n",
    "2. Petal Width   (c2)\n",
    "3. Sepal Length  (c3)\n",
    "4. Sepal Width   (c4)\n",
    "\n",
    "There are 3 output classes: Setosa, Versicolor, and Virginica.\n",
    "In our output datset, we have simplified this data by making classes simply 1, 2, 3.\n",
    "\n",
    "Here's an example of what the dataset looks like\n",
    "\n",
    "| c1  | c2  | c3  | c4  | label | \n",
    "|-----|-----|-----|-----|-------| \n",
    "| 6.4 | 2.8 | 5.6 | 2.2 | 3     | \n",
    "| 5.0 | 2.3 | 3.3 | 1.0 | 2     | \n",
    "| 4.9 | 2.5 | 4.5 | 1.7 | 3     | \n",
    "| 4.9 | 3.1 | 1.5 | 0.1 | 1     | \n",
    "| 5.7 | 3.8 | 1.7 | 0.3 | 1     | \n",
    "| 4.4 | 3.2 | 1.3 | 0.2 | 1     | \n",
    "| 5.4 | 3.4 | 1.5 | 0.4 | 1     | \n",
    "| 6.9 | 3.1 | 5.1 | 2.3 | 3     | \n",
    "| 6.7 | 3.1 | 4.4 | 1.4 | 2     | \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import datetime as dt \n",
    "\n",
    "\n",
    "\n",
    "from bigdl.dataset.transformer import *\n",
    "from bigdl.dataset.base import *\n",
    "from bigdl.nn.layer import *\n",
    "from bigdl.nn.criterion import *\n",
    "from bigdl.optim.optimizer import *\n",
    "from bigdl.util.common import *\n",
    "from utils import *\n",
    "from bigdl.models.ml_pipeline.dl_classifier import *\n",
    "\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.ml import  Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "init_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "These are parameters that can be changed:\n",
    "\n",
    "Explanation:\n",
    "\n",
    "1. Learning Rate:  This indicates the \"step size\" of the gradient descent-type optimization functions. The larger the step size, the less of a chance of getting caught in a local minimum but too large may lead to very poor results.\n",
    "\n",
    "2. Training Epochs: the number of cycles of training that we use.\n",
    "\n",
    "3. Batch size: The size of the batch (with replacement) that we take per training iteration.\n",
    "\n",
    "4. N_input: Number of input dimensions\n",
    "\n",
    "5. N_Classes: Number of output classes for classification problem.\n",
    "\n",
    "6. N_Hidden_1: Number of hidden layer neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "training_epochs = 100\n",
    "batch_size = 16\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 4\n",
    "n_classes = 3\n",
    "n_hidden = 3 # 1st layer number of features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sizing the Hidden Layer(s)\n",
    "\n",
    "Sizing hidden layers can be a challenge.  The best way to figure this out is to do it\n",
    "empirically.  However, we may need a \"rule of thumb\" to start.  Here is a good rule of thumb:\n",
    "\n",
    "First Hidden Layer:\n",
    "```\n",
    "n_hidden_1 = np.sqrt(np.sqrt((n_classes + 2) * n_input) + 2 * np.sqrt(n_input /(n_classes+2.)))\n",
    "```\n",
    "\n",
    "Second Hidden Layer:  (if needed)\n",
    "```\n",
    "n_hidden_2 = n_classes * np.sqrt(n_input / (n_classes + 2.))\n",
    "```\n",
    "\n",
    "In this case, we have a **VERY** simple dataset.  We may not need two hidden layers. Let's see what we have.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer 1 (Guess) : 2.50219710195\n",
      "Hidden layer 2 (Guess) : 2.683281573\n"
     ]
    }
   ],
   "source": [
    "# Number of hidden layers\n",
    "\n",
    "n_hidden_guess = np.sqrt(np.sqrt((n_classes + 2) * n_input) + 2 * np.sqrt(n_input /(n_classes+2.)))\n",
    "print(\"Hidden layer 1 (Guess) : \" + str(n_hidden_guess))\n",
    "\n",
    "n_hidden_guess_2 = n_classes * np.sqrt(n_input / (n_classes + 2.))\n",
    "print(\"Hidden layer 2 (Guess) : \" + str(n_hidden_guess_2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "Each hidden layer should around 2-3 input neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.sqrt(np.sqrt((n_classes+2) * n_input) + 2 * np.sqrt(n_input /(n_classes+2)))\n",
    "#and in the second hidden layer, the optimal number of hidden nodes is: m*sqrt[N/(m+2)],\n",
    "n_classes * np.sqrt(n_input / (n_classes + 2.))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Let's load the data into Spark Dataframes, and we'll cast everything to be double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_training = spark.read.csv(\"../data/iris/iris_training.csv\", header=True, inferSchema=\"true\", mode=\"DROPMALFORMED\")\n",
    "iris_test = spark.read.csv(\"../data/iris/iris_test.csv\", header=True, inferSchema=\"true\", mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_training = iris_training.select([col(c).cast(\"double\") for c in iris_training.columns])\n",
    "iris_test = iris_test.select([col(c).cast(\"double\") for c in iris_test.columns])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a Spark MLlib pipeline\n",
    "\n",
    "We will use a Spark MLLib pipeline to do two things:\n",
    "\n",
    "1. Extract a feature vector into a new column called \"assembled\" (using VectorAssembler).\n",
    "2. Use StandardScaler to scale the vector values by mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler =  VectorAssembler(inputCols=['c1','c2','c3','c4'], outputCol=\"assembled\")\n",
    "scaler = StandardScaler(inputCol=\"assembled\", outputCol=\"features\")\n",
    "pipeline = Pipeline(stages = [assembler, scaler])\n",
    "pipelineTraining = pipeline.fit(iris_training)\n",
    "iris_data_training = pipelineTraining.transform(iris_training)\n",
    "pipelineTest = pipeline.fit(iris_test)\n",
    "iris_data_test = pipelineTraining.transform(iris_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+-----+\n",
      "|features                                                                    |label|\n",
      "+----------------------------------------------------------------------------+-----+\n",
      "|[7.3683612551017434,6.554983394668502,3.07337626655598,2.813157930275381]   |3.0  |\n",
      "|[5.7565322305482365,5.384450645620555,1.8110967285062027,1.2787081501251731]|2.0  |\n",
      "|[5.641401585937273,5.8526637452397345,2.469677357053913,2.1738038552127943] |3.0  |\n",
      "|[5.641401585937273,7.257303044097271,0.8232257856846377,0.12787081501251732]|1.0  |\n",
      "|[6.56244674282499,8.896048892764396,0.9329892237759226,0.38361244503755193] |1.0  |\n",
      "|[5.065748362882449,7.491409593906861,0.7134623475933526,0.25574163002503464]|1.0  |\n",
      "|[6.2170548089920965,7.959622693526039,0.8232257856846377,0.5114832600500693]|1.0  |\n",
      "|[7.944014478156568,7.257303044097271,2.798967671327768,2.941028745287898]   |3.0  |\n",
      "|[7.713753188934637,7.257303044097271,2.4147956380082705,1.7901914101752423] |2.0  |\n",
      "|[5.871662875159201,8.661942342954807,0.8232257856846377,0.5114832600500693] |1.0  |\n",
      "+----------------------------------------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_data_training.select('features', 'label').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Pipeline API to set up neural network classifier\n",
    "\n",
    "We will now use the Pipeline API to set up a neural network classifier. The parameters and results are very similar to the previous example, but this time around we are using the pipeline API.\n",
    "\n",
    "This is totally integrated with our existing Spark ML workflows!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating: createSequential\n",
      "creating: createLinear\n",
      "creating: createLinear\n",
      "creating: createLogSoftMax\n",
      "creating: createClassNLLCriterion\n",
      "creating: createDLClassifier\n",
      "\n",
      "initial model training finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bigDLModel = Sequential().add(Linear(n_input, n_hidden)).add(Linear(n_hidden, n_classes)).add(LogSoftMax())\n",
    "classnll_criterion = ClassNLLCriterion()\n",
    "dlClassifier = DLClassifier(model=bigDLModel, criterion=classnll_criterion, feature_size=[n_input])\n",
    "dlClassifier.setLabelCol(\"label\").setMaxEpoch(training_epochs).setBatchSize(16).setLearningRate(learning_rate)\n",
    "model = dlClassifier.fit(iris_data_training)\n",
    "print(\"\\ninitial model training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[c1: double, c2: double, c3: double, c4: double, label: double, assembled: vector, features: vector, prediction: double]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coerce the outpu to be a Dataframe object -- return object is a JavaObject by defaul.\n",
    "\n",
    "from pyspark.sql import DataFrame, SQLContext\n",
    "predictionDF = DataFrame(model.transform(iris_data_test), SQLContext(sc))\n",
    "predictionDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----+-----------------+--------------------+----------+\n",
      "| c1| c2| c3| c4|label|        assembled|            features|prediction|\n",
      "+---+---+---+---+-----+-----------------+--------------------+----------+\n",
      "|5.9|3.0|4.2|1.5|  2.0|[5.9,3.0,4.2,1.5]|[6.79270803204692...|       2.0|\n",
      "|6.9|3.1|5.4|2.1|  3.0|[6.9,3.1,5.4,2.1]|[7.94401447815656...|       3.0|\n",
      "|5.1|3.3|1.7|0.5|  1.0|[5.1,3.3,1.7,0.5]|[5.87166287515920...|       1.0|\n",
      "|6.0|3.4|4.5|1.6|  2.0|[6.0,3.4,4.5,1.6]|[6.90783867665788...|       2.0|\n",
      "|5.5|2.5|4.0|1.3|  2.0|[5.5,2.5,4.0,1.3]|[6.33218545360306...|       2.0|\n",
      "|6.2|2.9|4.3|1.3|  2.0|[6.2,2.9,4.3,1.3]|[7.13809996587981...|       2.0|\n",
      "|5.5|4.2|1.4|0.2|  1.0|[5.5,4.2,1.4,0.2]|[6.33218545360306...|       1.0|\n",
      "|6.3|2.8|5.1|1.5|  3.0|[6.3,2.8,5.1,1.5]|[7.25323061049077...|       2.0|\n",
      "|5.6|3.0|4.1|1.3|  2.0|[5.6,3.0,4.1,1.3]|[6.44731609821402...|       2.0|\n",
      "|6.7|2.5|5.8|1.8|  3.0|[6.7,2.5,5.8,1.8]|[7.71375318893463...|       3.0|\n",
      "|7.1|3.0|5.9|2.1|  3.0|[7.1,3.0,5.9,2.1]|[8.17427576737849...|       3.0|\n",
      "|4.3|3.0|1.1|0.1|  1.0|[4.3,3.0,1.1,0.1]|[4.95061771827148...|       1.0|\n",
      "|5.6|2.8|4.9|2.0|  3.0|[5.6,2.8,4.9,2.0]|[6.44731609821402...|       3.0|\n",
      "|5.5|2.3|4.0|1.3|  2.0|[5.5,2.3,4.0,1.3]|[6.33218545360306...|       2.0|\n",
      "|6.0|2.2|4.0|1.0|  2.0|[6.0,2.2,4.0,1.0]|[6.90783867665788...|       2.0|\n",
      "|5.1|3.5|1.4|0.2|  1.0|[5.1,3.5,1.4,0.2]|[5.87166287515920...|       1.0|\n",
      "|5.7|2.6|3.5|1.0|  2.0|[5.7,2.6,3.5,1.0]|[6.56244674282499...|       2.0|\n",
      "|4.8|3.4|1.9|0.2|  1.0|[4.8,3.4,1.9,0.2]|[5.52627094132630...|       1.0|\n",
      "|5.1|3.4|1.5|0.2|  1.0|[5.1,3.4,1.5,0.2]|[5.87166287515920...|       1.0|\n",
      "|5.7|2.5|5.0|2.0|  3.0|[5.7,2.5,5.0,2.0]|[6.56244674282499...|       3.0|\n",
      "+---+---+---+---+-----+-----------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "Calculate Precision, Recall and the Area Under the Precision / Recall curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Area under precision-recall curve: = 1.0\n",
      "\n",
      "recall = 0.933333333333\n",
      "\n",
      "Precision = 0.933333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[c1: double, c2: double, c3: double, c4: double, label: double, assembled: vector, features: vector, prediction: double]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionDF.cache()\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\n",
    "auPRC = evaluator.evaluate(predictionDF)\n",
    "print(\"\\nArea under precision-recall curve: = \" + str(auPRC))\n",
    "    \n",
    "recall = MulticlassClassificationEvaluator(metricName=\"weightedRecall\").evaluate(predictionDF)\n",
    "print(\"\\nrecall = \" + str(recall))\n",
    "\n",
    "precision = MulticlassClassificationEvaluator(metricName=\"weightedPrecision\").evaluate(predictionDF)\n",
    "print(\"\\nPrecision = \" + str(precision))\n",
    "predictionDF.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More evaluations: Accuracy and Confusion Matrix\n",
    "\n",
    "Use predict on the validation dataset, and then calcualte the accuracy and the\n",
    "confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(predictionDF.select('prediction').collect())\n",
    "y_true = np.array(predictionDF.select('label').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is 93.33%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAHVCAYAAADSAqClAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMDoaVgAgNHTsAAAo/f/AM8FR00mEaaaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd80cec6750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"The prediction accuracy is %.2f%%\"%(acc*100))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm.shape\n",
    "df_cm = pd.DataFrame(cm)\n",
    "plt.figure(figsize = (10,8))\n",
    "sn.heatmap(df_cm, annot=True,fmt='d');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
